{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN40GpxKm7318p0UFUpDF0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithya70/Multi-Modal-AI-Processing/blob/main/Multi-Modal%20AI%20Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLOqDEB0YoQJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "RveIhAopY3_P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "R_MZXADXY5Va",
        "outputId": "9794d4be-b4b5-46ed-e0e8-f00a3e92246f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d515ca0-001b-41fa-aba2-34ae8c078c01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d515ca0-001b-41fa-aba2-34ae8c078c01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ad1thya70\",\"key\":\"d632bc2d9c7c1154cc6e324f7105858d\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "4l-VH4OrY_zk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "CMHY781IZIoQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "YSQe9Vd3ZKtD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNLdIrSnZNQQ",
        "outputId": "7c504d5b-68cc-44ed-8723-9e01848fae53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                           title                                              size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "anandshaw2001/netflix-movies-and-tv-shows                     Netflix Movies and TV Shows                         1MB  2025-01-03 10:33:01          13939        363  1.0              \n",
            "asinow/car-price-dataset                                      Car Price Dataset                                 135KB  2025-01-26 19:53:28           3394         50  1.0              \n",
            "ankushpanday1/alzheimers-prediction-dataset-global            Alzheimer’s Prediction Dataset (Global)             1MB  2025-01-30 14:38:39           1469         32  1.0              \n",
            "muhammadhabibna/hospital-data-in-indonesia                    Hospital data in Indonesia                        144KB  2025-02-01 04:11:47            659         25  1.0              \n",
            "ankushpanday1/usa-statewise-daily-temperature-december-2024   USA Statewise Daily Temperature: December 2024      6KB  2025-01-28 05:35:09            852         24  1.0              \n",
            "asinow/airplane-price-dataset                                 Airplane Price Dataset                            238KB  2025-01-28 18:36:41           2145         34  0.9411765        \n",
            "ankushpanday1/leukemia-cancer-risk-prediction-dataset         Leukemia Cancer Risk Prediction Dataset             3MB  2025-02-02 06:43:20            393         25  1.0              \n",
            "himelsarder/road-accident-survival-dataset                    Road Accident Survival Dataset                      1KB  2025-01-18 06:00:32           2080         26  1.0              \n",
            "ashaychoudhary/anxiety-attack-factors-symptoms-and-severity   Anxiety Attack : Factors, Symptoms, and Severity  244KB  2025-01-19 11:56:21           3394         58  1.0              \n",
            "ankushpanday1/global-road-accidents-dataset                   Global Road Accidents Dataset                      12MB  2025-01-25 04:22:29           2414         60  1.0              \n",
            "asinow/laptop-price-dataset                                   Laptop Price Dataset                              181KB  2025-02-01 04:20:16            630         24  1.0              \n",
            "shriyashjagtap/heart-attack-risk-assessment-dataset           Heart Attack Risk Assessment Dataset               49KB  2025-01-31 15:41:10            898         34  1.0              \n",
            "samithsachidanandan/gdp-by-country-1960-2023                  GDP By Country 1960 - 2023 🌍                       80KB  2025-01-24 16:26:01            974         26  1.0              \n",
            "oktayrdeki/traffic-accidents                                  Traffic Accidents                                   5MB  2025-01-20 10:33:44           3188         63  1.0              \n",
            "ashaychoudhary/the-power-of-social-media-engagement           The Power Of Social Media Engagement               25KB  2025-01-31 05:08:21            797         23  1.0              \n",
            "ruchikakumbhar/placement-prediction-dataset                   Placement Prediction Dataset                      100KB  2025-01-20 06:48:57           1756         33  1.0              \n",
            "srgiomanhes/steam-games-dataset-2025                          Steam games Dataset 2025                            4MB  2025-01-27 20:07:57           1049         34  1.0              \n",
            "ashaychoudhary/dataset-mba-decision-after-bachelors           Dataset: MBA Decision After Bachelor's            284KB  2025-01-17 04:41:28           3078         68  1.0              \n",
            "ochid7/predict-the-weather                                    Predict the weather                                 2KB  2025-01-15 13:01:04           1063         22  1.0              \n",
            "ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training  Cafe Sales - Dirty Data for Cleaning Training     111KB  2025-01-17 19:49:39           3359         64  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqSrhH4ZZR6N",
        "outputId": "f26fbdc6-1fbb-495a-a5e2-53a0ba479818"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 806M/812M [00:08<00:00, 133MB/s]\n",
            "100% 812M/812M [00:09<00:00, 92.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit google-generativeai pillow kaggle pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSuM_yp-Z7_x",
        "outputId": "cf7e1ded-0f24-4dfc-f889-412a4e98d662"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.24.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"dogs-vs-cats.zip\"  # Ensure this matches your uploaded file name\n",
        "extract_folder = \"dogs-vs-cats\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(f\"Extracted to: {extract_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kelIVuj8b0ce",
        "outputId": "9ccc1900-35ad-4c33-81d5-02a2d6892227"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to: dogs-vs-cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define paths for the ZIP files\n",
        "data_folder = \"dogs-vs-cats\"  # Folder where the files were extracted\n",
        "train_zip = os.path.join(data_folder, \"train.zip\")\n",
        "test_zip = os.path.join(data_folder, \"test1.zip\")\n",
        "\n",
        "# Create extraction folders\n",
        "train_extract_folder = os.path.join(data_folder, \"train\")\n",
        "test_extract_folder = os.path.join(data_folder, \"test\")\n",
        "\n",
        "# Extract train.zip\n",
        "with zipfile.ZipFile(train_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(train_extract_folder)\n",
        "\n",
        "# Extract test1.zip\n",
        "with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(test_extract_folder)\n",
        "\n",
        "print(\"Extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZK3_g7varu5",
        "outputId": "6da707a0-5025-4ff8-fd75-f7445b20aed6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Set up API key\n",
        "genai.configure(api_key=\"AIzaSyC2gG5sL5SNBw33CrNyMmJ8aL9ateVNe0U\")\n",
        "\n",
        "# Initialize Gemini Model\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "2uPWMOyRa-oN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_response(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "text_prompt = \"Explain the importance of AI in healthcare.\"\n",
        "print(generate_text_response(text_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "oUCUw4wlbJiA",
        "outputId": "0cd8c4e8-57fe-49d4-ece0-d00b89f46aee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is rapidly transforming healthcare, offering the potential to revolutionize various aspects of patient care, research, and administration. Its importance stems from its ability to:\n",
            "\n",
            "**1. Improve Diagnostics and Treatment:**\n",
            "\n",
            "* **Faster and more accurate diagnoses:** AI algorithms can analyze medical images (X-rays, CT scans, MRIs) with remarkable speed and accuracy, often surpassing human capabilities in detecting subtle anomalies indicative of diseases like cancer, heart conditions, and neurological disorders.  This leads to earlier intervention and better treatment outcomes.\n",
            "* **Personalized medicine:** AI can analyze patient data (genetics, lifestyle, medical history) to predict individual risk factors for diseases and tailor treatment plans to optimize effectiveness and minimize side effects.\n",
            "* **Drug discovery and development:** AI accelerates the process of identifying potential drug candidates, predicting their efficacy and safety, and optimizing clinical trials, leading to faster development of new therapies.\n",
            "\n",
            "**2. Enhance Patient Care and Experience:**\n",
            "\n",
            "* **Virtual assistants and chatbots:**  These AI-powered tools provide patients with 24/7 access to information, appointment scheduling, medication reminders, and basic medical advice, improving patient engagement and reducing the burden on healthcare providers.\n",
            "* **Remote patient monitoring:** Wearable sensors and AI algorithms can continuously monitor vital signs and other health metrics, alerting healthcare professionals to potential problems and enabling timely interventions, particularly beneficial for patients with chronic conditions.\n",
            "* **Robotic surgery:** AI-assisted robotic surgery allows for greater precision, minimally invasive procedures, and faster recovery times.\n",
            "\n",
            "**3. Optimize Healthcare Operations and Efficiency:**\n",
            "\n",
            "* **Administrative tasks automation:** AI can automate tasks like scheduling appointments, billing, and insurance claims processing, freeing up healthcare professionals to focus on patient care.\n",
            "* **Predictive analytics:** AI can analyze large datasets to predict patient flow, hospital resource needs, and potential outbreaks of infectious diseases, allowing for proactive resource allocation and improved operational efficiency.\n",
            "* **Fraud detection:** AI algorithms can identify patterns indicative of healthcare fraud and abuse, helping to reduce costs and improve the integrity of the healthcare system.\n",
            "\n",
            "\n",
            "**4. Advance Research and Development:**\n",
            "\n",
            "* **Genomic analysis:** AI can analyze vast genomic datasets to identify genetic markers associated with diseases and develop targeted therapies.\n",
            "* **Clinical trial optimization:** AI can help design more efficient and effective clinical trials by identifying suitable participants, predicting trial outcomes, and optimizing treatment strategies.\n",
            "\n",
            "\n",
            "**However, it's crucial to acknowledge the challenges:**\n",
            "\n",
            "* **Data privacy and security:** Protecting sensitive patient data is paramount.\n",
            "* **Algorithmic bias:** AI algorithms can perpetuate existing biases in healthcare data, leading to disparities in care.\n",
            "* **Lack of transparency and explainability:** Understanding how AI algorithms arrive at their conclusions is crucial for building trust and ensuring accountability.\n",
            "* **Regulatory hurdles:**  Navigating regulatory frameworks for the use of AI in healthcare can be complex.\n",
            "* **Integration with existing systems:** Integrating AI technologies into existing healthcare infrastructure can be challenging and costly.\n",
            "\n",
            "\n",
            "Despite these challenges, the potential benefits of AI in healthcare are immense.  As the technology matures and addresses these challenges, it promises to significantly improve the quality, accessibility, and efficiency of healthcare worldwide.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Function to process image with a text prompt\n",
        "def process_image(image_path, text_prompt):\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Pass both the text prompt and the image to the model\n",
        "    response = model.generate_content([text_prompt, img])\n",
        "    return response.text\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/dogs-vs-cats/train/train/cat.1000.jpg\"  # Replace with your image path\n",
        "text_prompt = \"What is in this image?\"  # Add a text prompt\n",
        "print(process_image(image_path, text_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "XAoi5ewGbI8P",
        "outputId": "e7c15efa-01a1-46c2-fbc5-7c035846f4e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1209.94ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 655.41ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 202.03ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 227.62ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 202.36ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 204.48ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.73ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 202.82ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 177.01ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.12ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 227.49ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 202.88ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 177.78ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 228.09ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 203.21ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 177.16ms\n",
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 228.50ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a tuxedo kitten!  More specifically, the image shows a young, black and white tuxedo cat standing in a cage.  Part of another kitten is visible in the background.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
        "\n",
        "# Function to process image with a text prompt\n",
        "def process_image(image_path, text_prompt):\n",
        "    # Open the image using PIL\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Pass both the text prompt and the image to the model\n",
        "    response = model.generate_content([text_prompt, img])\n",
        "    return response.text\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/anime.jpeg\"  # Replace with your image path\n",
        "text_prompt = \"What is in this image?\"  # Add a text prompt\n",
        "print(process_image(image_path, text_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "TLI9pHmebMTe",
        "outputId": "0902b51f-3152-4d89-f69a-2b44046ed6e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is a collage of popular anime and manga characters.  Here are a few that I can identify:\n",
            "\n",
            "* **Top row (left to right):** Edward Elric (Fullmetal Alchemist), Saitama (One-Punch Man), Monkey D. Luffy (One Piece), Erza Scarlet (Fairy Tail), Goten (Dragon Ball Z), Goku (Dragon Ball Z), Naruto Uzumaki (Naruto), Natsu Dragneel (Fairy Tail), Ash Ketchum (Pokémon), Pikachu (Pokémon), Nami (One Piece), Izuku Midoriya (My Hero Academia), Shin-chan (Crayon Shin-chan)\n",
            "\n",
            "* **Bottom row (left to right):**  Likely Yuki Nagato (The Melancholy of Haruhi Suzumiya), Vegeta (Dragon Ball Z), Conan Edogawa (Detective Conan),  Kyon (The Melancholy of Haruhi Suzumiya), Doraemon (Doraemon), Gon Freecs (Hunter x Hunter), Ichigo Kurosaki (Bleach), Kirito (Sword Art Online), Sasuke Uchiha (Naruto),  and possibly Yukio Okumura (Blue Exorcist).\n",
            "\n",
            "\n",
            "It's a collection of characters from various shonen, and some seinen, series.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0dB_7Kkb0-0",
        "outputId": "7d765e77-c882-4230-a1a6-f3b7915a8397"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "\n",
        "# Set up Gemini API\n",
        "genai.configure(api_key=\"AIzaSyC2gG5sL5SNBw33CrNyMmJ8aL9ateVNe0U\")\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Gemini LLM Multi-Modal AI Hands-On\")\n",
        "st.subheader(\"Bring Your Own Dataset (Kaggle, Local, APIs)\")\n",
        "\n",
        "# Text Processing\n",
        "st.write(\"## Text Processing\")\n",
        "text_input = st.text_area(\"Enter a prompt:\")\n",
        "if st.button(\"Generate Text Response\"):\n",
        "    st.write(model.generate_content(text_input).text)\n",
        "\n",
        "# Image Processing\n",
        "st.write(\"## Image Processing\")\n",
        "uploaded_file = st.file_uploader(\"Upload an Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "if uploaded_file:\n",
        "    st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    if st.button(\"Analyze Image\"):\n",
        "        img = Image.open(uploaded_file)\n",
        "        st.write(model.generate_content(img).text)\n",
        "\n",
        "# Text + Image Processing\n",
        "st.write(\"## Text + Image Processing\")\n",
        "text_prompt_2 = st.text_area(\"Enter a text prompt for the image:\")\n",
        "if uploaded_file and text_prompt_2 and st.button(\"Analyze Text + Image\"):\n",
        "    img = Image.open(uploaded_file)\n",
        "    st.write(model.generate_content([text_prompt_2, img]).text)\n",
        "\n",
        "# Kaggle Dataset Integration\n",
        "st.write(\"## Load Kaggle Dataset\")\n",
        "dataset_name = st.text_input(\"Enter Kaggle dataset name:\")\n",
        "if st.button(\"Download Dataset\"):\n",
        "    import os\n",
        "    os.system(f\"kaggle datasets download -d {dataset_name} -p ./data && unzip ./data/{dataset_name}.zip -d ./data\")\n",
        "    st.write(f\"Downloaded {dataset_name} successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ4o0Ae4ga2J",
        "outputId": "97864941-cbdd-453f-e92a-2f511be499a9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"2FmFzkDXLyfLTlWyu2zlfi8ovSw_2t74v3BtP2DUCd6uwD7Bk\")"
      ],
      "metadata": {
        "id": "AzCpZICGeE5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4100e03e-5125-4557-ba76-4a9228adb4f5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501 &\n",
        "\n",
        "# Expose the app using ngrok\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(\"Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJA8669neTSr",
        "outputId": "4100efcf-0198-4d4a-d006-727b574fcb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.247.98.157:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTBM72lCinzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}